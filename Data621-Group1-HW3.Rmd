---
title: 'Data 621 Homework 3: Boston Crime Rates'
author: "Tommy Jenkins, Violeta Stoyanova, Todd Weigel, Peter Kowalchuk, Eleanor R-Secoquian"
date: "October, 2019"
output:
  html_document:
    number_sections: yes
    theme: paper
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(tidyr)
library(MASS)
library(psych)
library(kableExtra)
library(dplyr)
library(faraway)
library(gridExtra)
library(reshape2)
library(leaps)
library(pROC)
library(caret)
library(naniar)
library(pander)
library(pROC)

crimeTrain <- read.csv("crime-training-data_modified.csv")
crimeEval <- read.csv("crime-evaluation-data_modified.csv")
```

# OVERVIEW

In this homework assignment, we will explore, analyze and model a data set containing information on crime for various neighborhoods of a major city. Each record has a response variable indicating whether or not the crime rate is above the median crime rate (1) or not (0).

## Objective: 

The objective is to build a binary logistic regression model on the training data set to predict whether the neighborhood will be at risk for high crime levels.

# DATA EXPLORATION

## Data Summary 
```{r echo=FALSE, message=FALSE, warning=FALSE}
crimed1 <- describe(crimeTrain, na.rm = F)
crimed1$na_count <- sapply(crimeTrain, function(y) sum(length(which(is.na(y)))))
crimed1$na_count_perc <- sapply(crimeTrain, function(x) round(sum(is.na(x))/nrow(crimeTrain)*100,1))
```


```{r echo=FALSE,message=FALSE,warning=FALSE}
colsTrain<-ncol(crimeTrain)
colsEval<-ncol(crimeEval)
missingCol<-colnames(crimeTrain)[!(colnames(crimeTrain) %in% colnames(crimeEval))]
```

The dataset consists of two data files: training and evaluation. The training dataset contains `r colsTrain` columns, while the evaluation dataset contains `r colsEval`. The evaluation dataset is missing column `r missingCol` which represend our responce variable and defines whether the crime rate is above the median crime rate (1) or not (0). We will start by exploring the training data set since it will be the one used to generate the regression model.

```{r echo=FALSE,message=FALSE,warning=FALSE}
text<-"a test"
if(all(apply(crimeTrain,2,function(x) is.numeric(x)))==TRUE) {
  text<-"all data is numeric"
} else {
  text<-"not all data is numeric"
}
maxMeanMedianDiff<-round(max(abs(sapply(crimeTrain, median, na.rm = T) - sapply(crimeTrain, mean, na.rm = T))*100/(sapply(crimeTrain, max, na.rm = T)-sapply(crimeTrain, min, na.rm = T))),2)
```

First we see that `r text`. The dataset does contain one dummy variable to identify if the property borders the Charles River (1) or not (0). 

```{r echo=FALSE,message=FALSE,warning=FALSE}
nas<-as.data.frame(sapply(crimeTrain, function(x) sum(is.na(x))))
nasp<-as.data.frame(sapply(crimeTrain, function(x) round(sum(is.na(x))/nrow(crimeTrain)*100,1)))
colnames(nas)<-c("name")
maxna<-max(nas)
maxnaname<-rownames(nas)[nas$name==maxna]
percent<-round(maxna/nrow(crimeTrain)*100,1)
```

An important aspect of any dataset is to determine how much, if any, data is missing. We look at all the variables to see which if any have missing data. We look at the basic descriptive statistics as well as the missing data and their percentages:

```{r echo=FALSE,message=FALSE,warning=FALSE}
kable(crimed1, "html", escape = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = T) %>%
  column_spec(1, bold = T) %>%
  scroll_box(width = "100%", height = "500px")
sapply(crimeTrain, function(x) round(sum(is.na(x))/nrow(crimeTrain)*100,1))

vis_miss(crimeTrain)
#gg_miss_upset(crimeTrain)
head(crimeTrain)
```


## Missing and Invalid Data

No missing data was found in the dataset.

With missing data assessed, we can look into the data in more detail. To visualize this we plot histograms for each data. 


```{r echo=FALSE,message=FALSE,warning=FALSE}
attach(crimeTrain[,-1])
ggplot(gather(crimeTrain[,-1]), aes(value)) +
    geom_histogram(bins = 20) +
    facet_wrap(~key, scales = "free_x")
```

# DATA PREPARATION

## Fix missing values

No data was found missing.

## Mathematical transformations.

**Box Cox**

## Variable Creation / Removal 

To determine how we can combine variables to create new one we start by looking at a correlation plot. 

```{r echo = FALSE, message=FALSE}
cor(crimeTrain$target, crimeTrain[-c(1)], use="na.or.complete")

```
```{r echo = FALSE, message=FALSE}
corrplot::corrplot(cor(crimeTrain[,1:13]), method='square')

```

# BUILD MODELS

###General regression

We start by building a model with all the predictors in the dataset.

```{r}
m1<-glm(target~.,data=crimeTrain,family="binomial"(link="logit"))
summary(m1)
```

The Summary of this model shows several predictor are not relevant. We build a second model without these predictors.

```{r}
m1.1<-glm(target~nox+age+dis+rad+tax+ptratio+medv,data=crimeTrain,family="binomial"(link="logit"))
summary(m1.1)
```


###AIC Step Method

Another way of selecting which predictors to use in the model is by calculating the AIC of the model. This metric is similar to the adjusted R-square of a model in that it penalizes models with more predictors over simpler model with few predictors. We use Stepwise function in r to find the lowest AIC with different predictors.

```{r}
m2 <- step(m1)
summary(m2)
```

This reduces the predictors used in the model to these:
     zn
     nox
     age
     dis
     rad
     tax
     ptRation
     medv

It Removes these predictors:
     indus
     chas
     rm#

The AIC improves marginally from 218.05 (our original general model) to 215.32, but we also benefit by having a simpler model less prone to overfitting.

Also, tThe predictors in the model now are all signficant (under 0.05 pr level) and all but one under .01 or very significant. Which is much improved over the prior model

###BIC Method

To determine the number of predictors and hich predictors to be used we will use the Bayesian Information Criterion (BIC).
```{r}
regfit.full <- regsubsets(factor(target) ~ ., data=crimeTrain)
par(mfrow = c(1,2))
reg.summary <- summary(regfit.full)
plot(reg.summary$bic, xlab="Number of Predictors", ylab="BIC", type="l", main="Subset Selection Using BIC")
BIC_num <- which.min(reg.summary$bic) 
points(BIC_num, reg.summary$bic[BIC_num], col="red", cex=2, pch=20)
plot(regfit.full, scale="bic", main="Predictors vs. BIC")
par(mfrow = c(1,1))
```
The plot on the right shows that the number of predictors with the lowest BIC are `nox` , `age`, `rad`, and `medv`. We will use those predictors to build the next model
```{r}
m3 <- glm(target ~ nox + age + rad + medv, family=binomial, data = crimeTrain)

crimeTrain$predicted_m3<- predict(m3, crimeTrain, type='response')
crimeTrain$target_m3$target <- ifelse(crimeTrain$predicted_m3>0.5, 1, 0)
pander::pander(summary(m3))
```

# SELECT MODELS
## Compare Model Statistics

###Model 1 - General Model

####Complete general model

**ROC Curve**
```{r}
targethat<-predict(m1,type="response")

g<-roc(target~targethat,data=crimeTrain)
plot(g)
```

**Confusion Matrix**
```{r}
targethat[targethat<0.5]<-0
targethat[targethat>=0.5]<-1
table(targethat,crimeTrain$target)
```

**Create a binned diagnostic plot of residuals vs prediction**
There are definite patterns here, which bear investigating.

```{r}
crimeMut <- mutate(crimeTrain, Residuals = residuals(m1), linPred = predict(m1))
grpCrime <- group_by(crimeMut, cut(linPred, breaks=unique(quantile(linPred, (0:25/26)))))

diagCrime <- summarise(grpCrime, Residuals = mean(Residuals), linPred = mean(linPred))
plot(Residuals ~ linPred, data = diagCrime, xlab="Linear Predictor")
```

**Plot leverages.**

```{r}
halfnorm(hatvalues(m1))
```

We don't see any strong outliers with the leverage plot.  The points identified (14,18) are essentially in the plot of the line formed, so they are not likely pulling our model in any direction.

**Plot Goodness of fit**
```{r}
linPred <- predict(m1)


crimeMut <- mutate(crimeTrain, predProb = predict(m1, type = "response"))
grpCrime <- group_by(crimeMut, cut(linPred, breaks = unique(quantile(linPred, (0:25)/26))))

#hosmer-lemeshow stat
hlDf <- summarise(grpCrime, y= sum(target), pPred=mean(predProb), count = n())

hlDf <- mutate(hlDf, se.fit=sqrt(pPred * (1-(pPred)/count)))


ggplot(hlDf,aes(x=pPred,y=y/count,ymin=y/count-2*se.fit,ymax=y/count+2*se.fit)) +
    geom_point()+geom_linerange(color=grey(0.75))+geom_abline(intercept=0,slope=1) +
    xlab("Predicted Probability") +
    ylab("Observed Proportion")
```

We see that our predictors fall close to the line.  (Note to group, need do adjust the min max line)

####Reduced general model

**ROC Curve**
```{r}
targethat<-predict(m1.1,type="response")

g<-roc(target~targethat,data=crimeTrain)
plot(g)
```

**Confusion Matrix**
```{r}
targethat[targethat<0.5]<-0
targethat[targethat>=0.5]<-1
table(targethat,crimeTrain$target)
```

**Create a binned diagnostic plot of residuals vs prediction**
There are definite patterns here, which bear investigating.

```{r}
crimeMut <- mutate(crimeTrain, Residuals = residuals(m1.1), linPred = predict(m1.1))
grpCrime <- group_by(crimeMut, cut(linPred, breaks=unique(quantile(linPred, (0:25/26)))))

diagCrime <- summarise(grpCrime, Residuals = mean(Residuals), linPred = mean(linPred))
plot(Residuals ~ linPred, data = diagCrime, xlab="Linear Predictor")
```

**Plot leverages.**

```{r}
halfnorm(hatvalues(m1.1))
```

We don't see any strong outliers with the leverage plot.  The points identified (14,18) are essentially in the plot of the line formed, so they are not likely pulling our model in any direction.

**Plot Goodness of fit**
```{r}
linPred <- predict(m1.1)


crimeMut <- mutate(crimeTrain, predProb = predict(m1.1, type = "response"))
grpCrime <- group_by(crimeMut, cut(linPred, breaks = unique(quantile(linPred, (0:25)/26))))

#hosmer-lemeshow stat
hlDf <- summarise(grpCrime, y= sum(target), pPred=mean(predProb), count = n())

hlDf <- mutate(hlDf, se.fit=sqrt(pPred * (1-(pPred)/count)))


ggplot(hlDf,aes(x=pPred,y=y/count,ymin=y/count-2*se.fit,ymax=y/count+2*se.fit)) +
    geom_point()+geom_linerange(color=grey(0.75))+geom_abline(intercept=0,slope=1) +
    xlab("Predicted Probability") +
    ylab("Observed Proportion")
```

We see that our predictors fall close to the line.  (Note to group, need do adjust the min max line)

###Model 2 - AIC Model

**ROC Curve**
```{r}
targethat<-predict(m2,type="response")
g<-roc(target~targethat,data=crimeTrain)
plot(g)
```

**Confusion Matrix**
```{r}
targethat[targethat<0.5]<-0
targethat[targethat>=0.5]<-1
table(targethat,crimeTrain$target)
```

**Create a binned diagnostic plot of residuals vs prediction**
There are definite patterns here, which bear investigating.

```{r}
crimeMut <- mutate(crimeTrain, Residuals = residuals(m2), linPred = predict(m2))
grpCrime <- group_by(crimeMut, cut(linPred, breaks=unique(quantile(linPred, (0:25/26)))))

diagCrime <- summarise(grpCrime, Residuals = mean(Residuals), linPred = mean(linPred))
plot(Residuals ~ linPred, data = diagCrime, xlab="Linear Predictor")
```

**Plot leverages.**

```{r}
halfnorm(hatvalues(m2))
```

We don't see any strong outliers with the leverage plot.  The points identified (14,18) are essentially in the plot of the line formed, so they are not likely pulling our model in any direction.

**Plot Goodness of fit**
```{r}
linPred <- predict(m2)


crimeMut <- mutate(crimeTrain, predProb = predict(m2, type = "response"))
grpCrime <- group_by(crimeMut, cut(linPred, breaks = unique(quantile(linPred, (0:25)/26))))

#hosmer-lemeshow stat
hlDf <- summarise(grpCrime, y= sum(target), pPred=mean(predProb), count = n())

hlDf <- mutate(hlDf, se.fit=sqrt(pPred * (1-(pPred)/count)))


ggplot(hlDf,aes(x=pPred,y=y/count,ymin=y/count-2*se.fit,ymax=y/count+2*se.fit)) +
    geom_point()+geom_linerange(color=grey(0.75))+geom_abline(intercept=0,slope=1) +
    xlab("Predicted Probability") +
    ylab("Observed Proportion")
```

We see that our predictors fall close to the line.  (Note to group, need do adjust the min max line)



###Model 3 - BIC Model
```{r}
targethat<-predict(m3,type="response")

g<-roc(target~targethat,data=crimeTrain)
plot(g)

targethat[targethat<0.5]<-0
targethat[targethat>=0.5]<-1
table(targethat,crimeTrain$target)
```

**Create a binned diagnostic plot of residuals vs prediction**
There are definite patterns here, which bear investigating.

```{r}
crimeMut <- mutate(crimeTrain, Residuals = residuals(m3), linPred = predict(m3))
grpCrime <- group_by(crimeMut, cut(linPred, breaks=unique(quantile(linPred, (0:25/26)))))

diagCrime <- summarise(grpCrime, Residuals = mean(Residuals), linPred = mean(linPred))
plot(Residuals ~ linPred, data = diagCrime, xlab="Linear Predictor")
```

**Plot leverages.**

```{r}
halfnorm(hatvalues(m3))
```

We don't see any strong outliers with the leverage plot.  The points identified (14,18) are essentially in the plot of the line formed, so they are not likely pulling our model in any direction.

**Plot Goodness of fit**
```{r}
linPred <- predict(m3)


crimeMut <- mutate(crimeTrain, predProb = predict(m3, type = "response"))
grpCrime <- group_by(crimeMut, cut(linPred, breaks = unique(quantile(linPred, (0:25)/26))))

#hosmer-lemeshow stat
hlDf <- summarise(grpCrime, y= sum(target), pPred=mean(predProb), count = n())

hlDf <- mutate(hlDf, se.fit=sqrt(pPred * (1-(pPred)/count)))


ggplot(hlDf,aes(x=pPred,y=y/count,ymin=y/count-2*se.fit,ymax=y/count+2*se.fit)) +
    geom_point()+geom_linerange(color=grey(0.75))+geom_abline(intercept=0,slope=1) +
    xlab("Predicted Probability") +
    ylab("Observed Proportion")
```

We see that our predictors fall close to the line.  (Note to group, need do adjust the min max line)


## Pick the best regression model


## Conclusion




# APPENDIX

**Code used in analysis**

